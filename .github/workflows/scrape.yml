name: scrape-news
on:
  schedule:
    - cron: "0 23 * * *"   # 23:00 UTC = 18:00 America/Bogota
  workflow_dispatch: {}
permissions:
  contents: write
jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run pipeline
        run: |
          python - <<'PY'
          import sys
          # Asegura que el repo raíz está en sys.path:
          sys.path.append('.')
          # Importa desde el paquete 'src' (requiere src/__init__.py):
          from src.pipeline import run_all, save_daily_and_master
          from src.balance import stratified_balance
          from src.utils import logger
          
          df_fc, df_nw = run_all()
          if len(df_fc) > 0:
            df_fc = stratified_balance(df_fc)
          save_daily_and_master(df_fc, df_nw)
          logger.info(f"factcheck={len(df_fc)} news={len(df_nw)}")
          PY
          



    
      - name: Commit outputs
        run: |
          git config user.name "github-actions"
          git config user.email "github-actions@users.noreply.github.com"
          git add -A
          if git diff --cached --quiet; then
            echo "No changes to commit."
          else
            now=$(date -u +"%Y-%m-%d %H:%M:%S UTC")
            git commit -m "data: daily scrape @ $now"
            git push
          fi
